import redis
from app.redis.vector_search import VectorSearchIndex
from app.redis.debug_utils import RedisIndexDebugger
import numpy as np
from typing import List, Dict, Any
import time
import uuid
import hashlib


def get_redis_client(redis_url: str) -> redis.Redis:
    """
    Redis í´ë¼ì´ì–¸íŠ¸ ìƒì„± ìœ í‹¸ í•¨ìˆ˜ (decode_responses=False ê³ ì •)
    """
    return redis.Redis.from_url(redis_url, decode_responses=False)


class RedisVectorSearchHandler:
    """Redis 8 Vector Searchë¥¼ í™œìš©í•œ í•¸ë“¤ëŸ¬"""
    
    def __init__(self, 
                 embedding_model,
                 redis_url: str = "redis://localhost:6379",
                 index_name: str = "document_index"):
        """
        Redis Vector Search í•¸ë“¤ëŸ¬ ì´ˆê¸°í™”
        
        Args:
            embedding_model: LangChain ìž„ë² ë”© ëª¨ë¸
            redis_url: Redis ì„œë²„ URL
            index_name: ë²¡í„° ê²€ìƒ‰ ì¸ë±ìŠ¤ ì´ë¦„
        """
        try:
            self.embedding_model = embedding_model
            self.redis_url = redis_url
            self.index_name = index_name
            
            # Redis í´ë¼ì´ì–¸íŠ¸ ìƒì„± (ìœ í‹¸ í•¨ìˆ˜ ì‚¬ìš©)
            self.redis_client = get_redis_client(redis_url)
            
            # Vector Search ì¸ë±ìŠ¤ ì´ˆê¸°í™”
            self.vector_index = VectorSearchIndex(
                redis_client=self.redis_client,
                index_name=index_name,
                vector_dimension=1536,  # OpenAI text-embedding-3-small
                distance_metric="COSINE"
            )
            
            # ë””ë²„ê¹… ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”
            self.debugger = RedisIndexDebugger(self.redis_client)
            
            print(f"Redis Vector Search í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì™„ë£Œ: {redis_url}")
            
            # ì´ˆê¸°í™” í›„ ê°„ë‹¨í•œ ìƒíƒœ í™•ì¸
            self.debugger.full_diagnosis([index_name])
            
        except Exception as e:
            print(f"Redis Vector Search í•¸ë“¤ëŸ¬ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
            raise
    
    def save_embedding(self, key: str, text: str, metadata: dict) -> bool:
        """
        í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ ìž„ë² ë”©í•˜ì—¬ Vector Search ì¸ë±ìŠ¤ì— ì €ìž¥
        
        Args:
            key: ë¬¸ì„œ ê³ ìœ  í‚¤
            text: ìž„ë² ë”©í•  í…ìŠ¤íŠ¸
            metadata: ì €ìž¥í•  ë©”íƒ€ë°ì´í„°
            
        Returns:
            bool: ì €ìž¥ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # í…ìŠ¤íŠ¸ë¥¼ ìž„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜
            embedding = self.embedding_model.embed_query(text)
            
            # ë©”íƒ€ë°ì´í„° ì¤€ë¹„
            doc_metadata = metadata.copy()
            doc_metadata["text"] = text
            doc_metadata["timestamp"] = doc_metadata.get("timestamp", time.time())
            
            # Vector Search ì¸ë±ìŠ¤ì— ì¶”ê°€
            success = self.vector_index.add_document(
                doc_id=key,
                embedding=embedding,
                metadata=doc_metadata
            )
            
            if success:
                print(f"ë¬¸ì„œ ì €ìž¥ ì™„ë£Œ - ID: {key}")
            
            return success
            
        except Exception as e:
            print(f"ìž„ë² ë”© ì €ìž¥ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def search_similar_embeddings(self, 
                                 query_text: str,
                                 top_k: int = 5,
                                 similarity_threshold: float = 0.7) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ ì¿¼ë¦¬ë¡œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰
        
        Args:
            query_text: ê²€ìƒ‰í•  í…ìŠ¤íŠ¸
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            similarity_threshold: ìœ ì‚¬ë„ ìž„ê³„ê°’
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # ê²€ìƒ‰ ì‹œìž‘ ë¡œê·¸ ìƒëžµ
        
        try:
            # ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¥¼ ìž„ë² ë”©ìœ¼ë¡œ ë³€í™˜
            query_embedding = self.embedding_model.embed_query(query_text)
            
            # Vector Searchë¡œ ìœ ì‚¬ ë¬¸ì„œ ê²€ìƒ‰
            results = self.vector_index.search_similar(
                query_vector=query_embedding,
                top_k=top_k,
                score_threshold=similarity_threshold
            )
            
            print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ê²°ê³¼ (ìž„ê³„ê°’: {similarity_threshold})")
            
            return results
            
        except Exception as e:
            print(f"âŒ ìœ ì‚¬ ìž„ë² ë”© ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°„ë‹¨í•œ ì§„ë‹¨
            print(f"ðŸ©º ê²€ìƒ‰ ì˜¤ë¥˜ë¡œ ì¸í•œ ì§„ë‹¨:")
            self.debugger.full_diagnosis([self.index_name])
            
            return []
    
    def delete_embedding(self, key: str) -> bool:
        """
        ì €ìž¥ëœ ìž„ë² ë”© ì‚­ì œ
        
        Args:
            key: ì‚­ì œí•  ë¬¸ì„œì˜ í‚¤
            
        Returns:
            bool: ì‚­ì œ ì„±ê³µ ì—¬ë¶€
        """
        return self.vector_index.delete_document(key)
    
    def get_index_info(self) -> Dict[str, Any]:
        """
        ì¸ë±ìŠ¤ ì •ë³´ ì¡°íšŒ
        
        Returns:
            Dict: ì¸ë±ìŠ¤ ì •ë³´
        """
        return self.vector_index.get_index_info()

    def get_all_stored_documents(self) -> list:
        """Redisì— ì €ìž¥ëœ ëª¨ë“  ë¬¸ì„œë¥¼ ì¡°íšŒ"""
        try:
            all_keys = self.redis_client.keys(f"doc:{self.index_name}:*".encode('utf-8'))

            all_documents = []
            for key in all_keys:
                try:
                    key_str = key.decode('utf-8')
                    hash_data = self.redis_client.hgetall(key)

                    metadata = {}
                    text_content = None

                    for field, value in hash_data.items():
                        try:
                            field_str = field.decode('utf-8') if isinstance(field, bytes) else str(field)

                            # ìž„ë² ë”© ë²¡í„° í•„ë“œë“¤ì€ ì œì™¸ (ë°”ì´ë„ˆë¦¬ ë°ì´í„°)
                            if field_str in ['embedding_vector', 'content_vector']:
                                continue

                            # UTF-8 ë””ì½”ë”© ì‹œë„
                            if isinstance(value, bytes):
                                try:
                                    value_str = value.decode('utf-8')
                                except UnicodeDecodeError:
                                    # ë””ì½”ë”© ì‹¤íŒ¨ì‹œ ê±´ë„ˆë›°ê¸°
                                    continue
                            else:
                                value_str = str(value)

                            if field_str == 'text':
                                text_content = value_str
                            else:
                                metadata[field_str] = value_str

                        except Exception as e:
                            # ê°œë³„ í•„ë“œ ì²˜ë¦¬ ì˜¤ë¥˜ëŠ” ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰
                            continue

                    document_info = {
                        "redis_key": key_str,
                        "key": metadata.get("custom_key", metadata.get("id", "unknown")),
                        "metadata": metadata,
                        "text": text_content or "N/A"
                    }

                    all_documents.append(document_info)

                except Exception as e:
                    print(f"ë¬¸ì„œ ì²˜ë¦¬ ì˜¤ë¥˜ ({key}): {e}")
                    continue

            return all_documents

        except Exception as e:
            print(f"ì „ì²´ ë¬¸ì„œ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []

class SemanticCacheHandler:
    """
    Redis 8 ê¸°ë°˜ ì‹œë©˜í‹± ìºì‹œ í•¸ë“¤ëŸ¬ (ì§ˆë¬¸-ë‹µë³€ ìŒ, ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜)
    """
    def __init__(self, embedding_model, redis_url: str = "redis://localhost:6379", index_name: str = "semantic_cache_index"):
        self.embedding_model = embedding_model
        self.redis_url = redis_url
        self.index_name = index_name
        self.redis_client = get_redis_client(redis_url)
        
        # ë””ë²„ê¹… ìœ í‹¸ë¦¬í‹° ì´ˆê¸°í™”
        self.debugger = RedisIndexDebugger(self.redis_client)
        
        self.vector_index = VectorSearchIndex(
            redis_client=self.redis_client,
            index_name=index_name,
            vector_dimension=1536,  # OpenAI text-embedding-3-small
            distance_metric="COSINE"
        )
        
        # ì´ˆê¸°í™” í›„ ê°„ë‹¨í•œ ìƒíƒœ í™•ì¸
        self.debugger.full_diagnosis([index_name])

    def save_qa_pair(self, question: str, answer: str, metadata: dict = None) -> bool:
        """
        ì§ˆë¬¸-ë‹µë³€ ìŒì„ ìž„ë² ë”©í•˜ì—¬ ë²¡í„° ì¸ë±ìŠ¤ì— ì €ìž¥
        """
        try:
            embedding = self.embedding_model.embed_query(question)
            doc_metadata = metadata.copy() if metadata else {}
            doc_metadata["question"] = question
            doc_metadata["answer"] = answer
            doc_metadata["timestamp"] = doc_metadata.get("timestamp", time.time())
            doc_metadata["type"] = "semantic_cache"
            key = str(uuid.uuid4())
            return self.vector_index.add_document(
                doc_id=key,
                embedding=embedding,
                metadata=doc_metadata
            )
        except Exception as e:
            print(f"[SemanticCache] ì €ìž¥ ì˜¤ë¥˜: {e}")
            import traceback; traceback.print_exc()
            return False

    def search_similar_question(self, query: str, top_k: int = 3, score_threshold: float = 0.05):
        """
        ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ì§ˆë¬¸-ë‹µë³€ ìŒì„ score_threshold ê¸°ì¤€ìœ¼ë¡œ ê²€ìƒ‰
        """
        # ê²€ìƒ‰ ì‹œìž‘ ë¡œê·¸ ìƒëžµ
        
        try:
            embedding = self.embedding_model.embed_query(query)
            results = self.vector_index.search_similar(
                query_vector=embedding,
                top_k=top_k,
                score_threshold=score_threshold
            )
            
            # answer í•„ë“œë§Œ ì¶”ì¶œ
            formatted_results = [
                {
                    "question": r["metadata"].get("question"),
                    "answer": r["metadata"].get("answer"),
                    "similarity": r["similarity"]
                }
                for r in results
            ]
            
            print(f"âœ… ì‹œë©˜í‹± ìºì‹œ ê²€ìƒ‰ ì™„ë£Œ: {len(formatted_results)}ê°œ ê²°ê³¼")
            return formatted_results
            
        except Exception as e:
            print(f"âŒ [SemanticCache] ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            import traceback; traceback.print_exc()
            
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê°„ë‹¨í•œ ì§„ë‹¨
            print(f"ðŸ©º ì‹œë©˜í‹± ìºì‹œ ì˜¤ë¥˜ë¡œ ì¸í•œ ì§„ë‹¨:")
            self.debugger.full_diagnosis([self.index_name])
            
            return []


class EmbeddingsCacheHandler:
    """
    Redis ê¸°ë°˜ ìž„ë² ë”© ìºì‹œ í•¸ë“¤ëŸ¬ (í…ìŠ¤íŠ¸-SHA256 í•´ì‹œë¥¼ key, ìž„ë² ë”© bytesë¥¼ value)
    """
    def __init__(self, redis_url: str = "redis://localhost:6379", prefix: str = "embeddings_cache"):
        self.redis_url = redis_url
        self.prefix = prefix
        self.redis_client = get_redis_client(redis_url)

    def _make_key(self, text: str) -> str:
        h = hashlib.sha256(text.encode("utf-8")).hexdigest()
        return f"{self.prefix}:{h}"

    def get_embedding(self, text: str):
        key = self._make_key(text)
        value = self.redis_client.get(key)
        if value is not None:
            return np.frombuffer(value, dtype=np.float32)
        return None

    def set_embedding(self, text: str, embedding: np.ndarray):
        key = self._make_key(text)
        self.redis_client.set(key, embedding.astype(np.float32).tobytes())
